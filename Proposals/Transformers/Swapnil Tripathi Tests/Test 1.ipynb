{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DeepLense: Multi-Class Classification**\n"
      ],
      "metadata": {
        "id": "dahaWKsvkDjT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiEJHZ1SfgM5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzZ2nYLpf5o-"
      },
      "outputs": [],
      "source": [
        "!unzip -qq gdrive/MyDrive/dataset.zip\n",
        "print('Extraction done.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te19C3Swb1Lr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Augmentation**\n",
        "The dataset consists of strong lensing images of three classes: \n",
        "\n",
        "\n",
        "1. no substructure\n",
        "2. subhalo substructure \n",
        "3. vortex substructure\n",
        "\n",
        "\n",
        "The dataset is already normalized so to an extent its already in a standard form.  \n",
        "Since the data is in the form of a list of images each having a single channel and a size of 150x150. We create a simple list of transforms to apply using transforms.Compose. We add a random horizontal flip with 0.5 probability and also enable random rotations up to 90 degrees. This allows our network to learn the image and with a new perspective each time and understand the underlying structure.  \n",
        "Since the images have a single channel, we can either copy the same image 3 times or we modify our model's first convolution layer to account for the single channel in our image."
      ],
      "metadata": {
        "id": "31bKWaaKkhbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(90),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.5], [0.5]),\n",
        "        #transforms.Lambda(lambda x: x.repeat(3,1,1))\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.5], [0.5]),\n",
        "        #transforms.Lambda(lambda x: x.repeat(3,1,1))\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "HAf9sx4ob5jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Loading**\n",
        "\n",
        "\n",
        "The dataset is structured as :\n",
        "```\n",
        "dataset\n",
        "└───train\n",
        "│   └───no\n",
        "        │   1.npy\n",
        "        │   2.npy\n",
        "        | ...\n",
        "│   └───sphere\n",
        "        │   1.npy\n",
        "        │   2.npy\n",
        "        | ...\n",
        "│   └───vort\n",
        "        │   1.npy\n",
        "        │   2.npy\n",
        "        | ...\n",
        "└───val\n",
        "│   └───no\n",
        "        │   1.npy\n",
        "        │   2.npy\n",
        "        | ...\n",
        "│   └───sphere\n",
        "        │   1.npy\n",
        "        │   2.npy\n",
        "        | ...\n",
        "│   └───vort\n",
        "        │   1.npy\n",
        "        │   2.npy\n",
        "        | ...\n",
        "```\n",
        "Which means we can use the DatasetFolder from the datasets module in the torchvision library with the original directory structure to generate our dataset."
      ],
      "metadata": {
        "id": "jcjGsZG6lf1l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ov-ZZEbde4a"
      },
      "outputs": [],
      "source": [
        "def npy_loader(path):\n",
        "    sample = torch.from_numpy(np.load(path))\n",
        "    return sample\n",
        "\n",
        "data_dir = 'dataset/'\n",
        "\n",
        "image_datasets = {x: datasets.DatasetFolder(\n",
        "    root=os.path.join(data_dir, x),\n",
        "    loader=npy_loader,\n",
        "    transform=data_transforms[x],\n",
        "    extensions=('.npy')\n",
        ") for x in ['train', 'val']}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create an iterable dataloader from the generated dataset."
      ],
      "metadata": {
        "id": "UmB9qPovmC-k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oBxtq9ghKrp"
      },
      "outputs": [],
      "source": [
        "dataloaders = {x: torch.utils.data.DataLoader(\n",
        "    image_datasets[x], batch_size=8,\n",
        "    shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "class_names = image_datasets['train'].classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Display the image data**\n",
        "\n",
        "\n",
        "Displaying the augmented images along with their class name."
      ],
      "metadata": {
        "id": "uZCpKBHlmZ8t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7fPK-hqhTsD"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.figure(figsize = (20,2))\n",
        "    plt.imshow(inp, cmap='binary')\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.pause(0.001)\n",
        "\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training the model**\n",
        "\n",
        "\n",
        "We prepare the model for training. We can transfer learn from a pretrained ResNet model for this task."
      ],
      "metadata": {
        "id": "cgexGd2Qm6eB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSEf3D9uhXc0"
      },
      "outputs": [],
      "source": [
        "# A function for the training loop.\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        model.train() # Set to training mode\n",
        "        train_acc = 0.0\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in dataloaders['train']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad() # Parameter gradients set to zero\n",
        "\n",
        "            # forward pass and tracking history\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                \n",
        "                # backward pass\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            train_acc += torch.sum(preds == labels.data)\n",
        "        scheduler.step()\n",
        "        train_loss = train_loss / dataset_sizes['train']\n",
        "        train_acc = train_acc / dataset_sizes['train']\n",
        "        print(f'Train accuracy : {train_acc} Train Loss : {train_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aw4Dx_Tha19"
      },
      "outputs": [],
      "source": [
        "# Using the resnet18 model with the pretrained=True\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "# Modifying the in_channels = 1 to account for single channel in our image\n",
        "model_ft.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "# Modifying our final connected layer's out_features to 3 corresponding to our 3 classes of lensing images.\n",
        "model_ft.fc = nn.Linear(in_features=num_ftrs, out_features=3)\n",
        "model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "# Using a learning rate scheduler to decay the learning rate of model parameters by 0.1 every 10th epoch.\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PXx9Jbdhb9m"
      },
      "outputs": [],
      "source": [
        "train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing**\n",
        "\n",
        "\n",
        "We test the model on our validation data."
      ],
      "metadata": {
        "id": "3H0MZ1F4ogjS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d7P0aR2mAK2"
      },
      "outputs": [],
      "source": [
        "y_score = []\n",
        "y_test = []\n",
        "\n",
        "for inputs, labels in dataloaders['val']:\n",
        "    model_ft.eval() # Setting to eval mode\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    y_test.append(labels.cpu().detach().numpy())\n",
        "    y_score.append(nn.functional.softmax(model_ft(inputs), dim=1).cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.concatenate(y_test)\n",
        "y_test_orig = y_test\n",
        "y_test = label_binarize(y_test, classes=[0, 1, 2])\n",
        "y_score = np.concatenate(y_score)"
      ],
      "metadata": {
        "id": "m3G_uA2phIBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy on the test set : {(y_score.argmax(axis=1) == y_test_orig).sum() / len(y_test) * 100}')"
      ],
      "metadata": {
        "id": "Djt9oRzPB4-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot ROC curve**"
      ],
      "metadata": {
        "id": "uptIvh0go9j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = y_test.shape[1]\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    \n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "    \n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [7, 5]\n",
        "\n",
        "lw = 2\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average (area = {})'\n",
        "               ''.format(round(roc_auc[\"micro\"],5)),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average (area = {})'\n",
        "               ''.format(round(roc_auc[\"macro\"],5)),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "labels = ['no sub', 'spherical', 'vortex']\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='{} (area = {})'\n",
        "             ''.format(labels[i], round(roc_auc[i],5)))\n",
        "\n",
        "# Plot the ROC \n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\", prop={\"size\":10})"
      ],
      "metadata": {
        "id": "HeGA9GbM1nvi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save the model**"
      ],
      "metadata": {
        "id": "Oh36daR1Gfyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ft.state_dict(), 'ct1_model.pth')"
      ],
      "metadata": {
        "id": "Afbl5guMGo7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate pdf"
      ],
      "metadata": {
        "id": "DWyP6CSGGKQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('ct1.ipynb')"
      ],
      "metadata": {
        "id": "2InrS2n5GK7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7ehLs-JZGPjb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ct1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}