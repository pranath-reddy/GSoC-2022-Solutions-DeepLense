{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ct3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DeepLense: Learning Mass of Dark Matter Halo**"
      ],
      "metadata": {
        "id": "iQpgDSCX37Bs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCxQifQFz4UD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar zxf gdrive/MyDrive/task_3.tgz"
      ],
      "metadata": {
        "id": "5VmKqjrd0dXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.nn import MSELoss, Module, Conv2d, Linear\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "cHCN0B7c5-OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = listdir('lens_data/')\n",
        "\n",
        "images_arr = []\n",
        "halo_mass_arr = []\n",
        "\n",
        "for f in files:\n",
        "    image, mass = np.load(f\"lens_data/{f}\", allow_pickle=True)\n",
        "    images_arr.append(image)\n",
        "    halo_mass_arr.append(mass)\n",
        "    \n",
        "images_arr = np.stack(np.expand_dims(images_arr, axis=1)).astype(np.float32) # (n, channel, width, height)\n",
        "halo_mass_arr = np.stack(np.expand_dims(halo_mass_arr, axis=1)).astype(np.float32) # (value)"
      ],
      "metadata": {
        "id": "DLcfZFwo6JuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(images_arr.shape)\n",
        "print(halo_mass_arr.shape)"
      ],
      "metadata": {
        "id": "j9Kmr0RSxUnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Displaying Lensing Images**"
      ],
      "metadata": {
        "id": "pzRURgo3J8uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "row = 3\n",
        "col = 3\n",
        "figure, axis = plt.subplots(row, col, figsize= (12,12), gridspec_kw= {'wspace':0, 'hspace':0.1})\n",
        "index=0\n",
        "\n",
        "for i in range(row):\n",
        "  for j in range(col):\n",
        "    img = axis[i][j].imshow(images_arr[index][0], cmap='gist_gray')\n",
        "    axis[i][j].set_title(f'fraction_mass: {halo_mass_arr[index][0]:.3}')\n",
        "    axis[i][j].axis('off')\n",
        "    index+=1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "32kuPKJjKA6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Augmentation**\n",
        "\n",
        "\n",
        "The data set consists of 20000 black and white (single channel) 150*150 unnormalized lensing images. We need to feature scale them by standardizing (z-score normalise) during the image preprocessing.  \n",
        "Also since the sample above shows that most images are centered, we will crop the image from the center."
      ],
      "metadata": {
        "id": "srr2I-IV2IV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the respective mean and standard deviation\n",
        "IMG_MEAN, IMG_STD = images_arr.mean(), images_arr.std()"
      ],
      "metadata": {
        "id": "XWLklkpo6SDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(IMG_STD, IMG_MEAN)"
      ],
      "metadata": {
        "id": "T5m07iObIBcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Normalize(mean=[IMG_MEAN], std=[IMG_STD])\n",
        "])"
      ],
      "metadata": {
        "id": "LsWkwxjg6cWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Loading**\n",
        "\n",
        "\n",
        "We use a custom dataset to store the images and the labels."
      ],
      "metadata": {
        "id": "JWcZXqK56OUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, x, y, indexes=None):\n",
        "        self.x = x[indexes]\n",
        "        self.y = y[indexes]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.x[idx], self.y[idx]\n",
        "        \n",
        "        image = torch.tensor(image).float()\n",
        "        label = torch.tensor(label).float()\n",
        "        \n",
        "        image = preprocess(image)\n",
        "\n",
        "        return  image, label"
      ],
      "metadata": {
        "id": "4ekrGA8z6epi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Split the dataset**"
      ],
      "metadata": {
        "id": "OP1GOW497ID8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(images_arr)\n",
        "t = int(0.9 * n)\n",
        "\n",
        "train_indices = np.arange(0, t)\n",
        "test_indices = np.arange(t, n)"
      ],
      "metadata": {
        "id": "EMywFv7l6dj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ImageDataset(images_arr, halo_mass_arr, train_indices)\n",
        "test_dataset = ImageDataset(images_arr, halo_mass_arr, test_indices)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "ytgmJlxw6gLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss Function**\n",
        "\n",
        "\n",
        "We will use the Mean Squared Error as the loss function."
      ],
      "metadata": {
        "id": "G0agsPpJ8COX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(pred, true):\n",
        "  return (np.abs(pred - true)**2).mean()"
      ],
      "metadata": {
        "id": "-5mWgQNR6lIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = MSELoss()"
      ],
      "metadata": {
        "id": "HsB2v1Muj6L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating the model**\n",
        "\n",
        "\n",
        "We will use the VGG13 CNN architecture modifying only the first and last layer for our custom input (single channel) and the regression output ie. 1."
      ],
      "metadata": {
        "id": "p5NWdqJv6yLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG13Regression(Module):\n",
        "    def __init__(self, channels, op_size):\n",
        "        super(VGG13Regression, self).__init__()\n",
        "        self.vgg13 = models.vgg13(pretrained=True)\n",
        "        self.vgg13.features[0] = Conv2d(\n",
        "            in_channels=channels,\n",
        "            out_channels=64,\n",
        "            kernel_size=(3,3),\n",
        "            stride=(2,2),\n",
        "            padding=(2,2),\n",
        "            bias=True\n",
        "        )\n",
        "        self.vgg13.classifier[6] = Linear(\n",
        "            in_features=4096,\n",
        "            out_features=op_size,\n",
        "            bias=True\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.vgg13(x)"
      ],
      "metadata": {
        "id": "XKUGhm-s6ivU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = VGG13Regression(1,1).to(device)"
      ],
      "metadata": {
        "id": "Rga76DQC6j1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A larger learning rate results in a relatively volatile model.\n",
        "lr = 1e-4\n",
        "\n",
        "num_of_epochs = 30\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "0ix0u6Tt6mgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training the model**"
      ],
      "metadata": {
        "id": "Se5h73Lq-VwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(num_of_epochs):\n",
        "    print(f'Epoch {epoch}/{num_of_epochs - 1}')\n",
        "    epoch_loss = 0.0\n",
        "    steps_in_epoch = 0\n",
        "    for _, (image, mass) in enumerate(train_data_loader):        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        image = image.to(device)\n",
        "        mass = mass.to(device)\n",
        "        \n",
        "        preds = model(image)\n",
        "        \n",
        "        b_loss = loss(preds, mass)\n",
        "        \n",
        "        b_loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += b_loss\n",
        "        steps_in_epoch += 1\n",
        "        \n",
        "    w_loss = (epoch_loss/steps_in_epoch).detach().item()\n",
        "    losses.append(w_loss)\n",
        "    print(f'Loss {w_loss}')"
      ],
      "metadata": {
        "id": "EgbzIGPJ6nUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Epochs vs Loss for Training data')\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.plot(np.array(losses))"
      ],
      "metadata": {
        "id": "k_soxWpYhPig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing**"
      ],
      "metadata": {
        "id": "GlTNXee1-gHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_mf_list = []\n",
        "real_mf_list = []\n",
        "\n",
        "for step, (image_d, fm_d) in enumerate(test_data_loader):\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    image_d = image_d.to(device)\n",
        "    fm_d = fm_d.to(device)\n",
        "    \n",
        "    preds = model(image_d)\n",
        "    predicted_mf_list.append(preds.cpu().detach().numpy())\n",
        "    real_mf_list.append(fm_d.cpu().numpy())\n",
        "\n",
        "predicted_mf_list = np.concatenate(predicted_mf_list)\n",
        "real_mf_list = np.concatenate(real_mf_list)"
      ],
      "metadata": {
        "id": "3p4lBLtyB5tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mse = mse(predicted_mf_list,real_mf_list)\n",
        "print(f'Test MSE: {test_mse}')"
      ],
      "metadata": {
        "id": "LUYtbhC7XEC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save the model**"
      ],
      "metadata": {
        "id": "bMNqBmdTNqPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'ct3_model.pth')"
      ],
      "metadata": {
        "id": "nsinepB6qFi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate pdf"
      ],
      "metadata": {
        "id": "9NgcHYzsQR0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('/content/drive/MyDrive/Colab Notebooks/ct3.ipynb')"
      ],
      "metadata": {
        "id": "NQl2S2zFQYyA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}